<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# 비조건적(Unconditional) 이미지 생성

이번 단락에서는 디퓨전 모델에게 비조건적(unconditional) 이미지 생성을 학습시키는 방법에 대해 다뤄보려고 합니다. 여기서 비조건적이란 말은 이미지 생성을 위한 어떠한 프롬프트나 문맥도 없다는 것을 의미합니다. 비조건적으로 훈련된 모델은 단순히 학습 데이터의 분포와 유사한 이미지를 생성하게 됩니다.



## 디펜던시 설치

스크립트를 실행하기 앞서, 먼저 다음과 같은 디펜던시들을 설치해야 합니다.

```bash
pip install diffusers[training] accelerate datasets
```

그 다음 [🤗Accelerate](https://github.com/huggingface/accelerate/) 환경을 이니셜라이즈해야합니다.

```bash
accelerate config
```



## 비조건적으로 꽃 이미지를 생성해보기

Oxford Flowers 데이터셋을 통해 DDPM UNet 모델을 훈련시켜봅시다.

```bash
accelerate launch train_unconditional.py \
  --dataset_name="huggan/flowers-102-categories" \
  --resolution=64 \
  --output_dir="ddpm-ema-flowers-64" \
  --train_batch_size=16 \
  --num_epochs=100 \
  --gradient_accumulation_steps=1 \
  --learning_rate=1e-4 \
  --lr_warmup_steps=500 \
  --mixed_precision=no \
  --push_to_hub
```
학습된 모델의 예시: https://huggingface.co/anton-l/ddpm-ema-flowers-64

전체 학습 시간은 4개의 V100 GPU를 기준으로 2시간이 소모됩니다.

<img src="https://user-images.githubusercontent.com/26864830/180248660-a0b143d0-b89a-42c5-8656-2ebf6ece7e52.png" width="700" />



## 비조건적으로 포켓몬스터 이미지를 생성해보기 

이번에는 포켓몬스터 데이터셋을 통해 DDPM UNet 모델을 훈련시켜봅시다.

```bash
accelerate launch train_unconditional.py \
  --dataset_name="huggan/pokemon" \
  --resolution=64 \
  --output_dir="ddpm-ema-pokemon-64" \
  --train_batch_size=16 \
  --num_epochs=100 \
  --gradient_accumulation_steps=1 \
  --learning_rate=1e-4 \
  --lr_warmup_steps=500 \
  --mixed_precision=no \
  --push_to_hub
```
학습된 모델의 예시: https://huggingface.co/anton-l/ddpm-ema-pokemon-64

마찬가지로 전체 학습 시간은 4개의 V100 GPU를 기준으로 2시간이 소모됩니다.

<img src="https://user-images.githubusercontent.com/26864830/180248200-928953b4-db38-48db-b0c6-8b740fe6786f.png" width="700" />



## 자체 데이터로 해보기

자체 데이터셋을 갖고 비조건적 이미지 생성을 진행하는 방법은 2가지가 있습니다.

* 해당 데이터셋 폴더를 `--train_data_dir` 인자로 전달하거나,
* 데이터셋 자체를 허브에 (보통은 비공개로) 업로드한 다음 `--dataset_name` 인자로 전달하는 것입니다.

**Note**: 혹시 자체 데이터셋을 만들어보고 싶으시다면, [해당 문서](https://huggingface.co/docs/datasets/image_process#image-datasets)를 참고해보세요.



### 폴더로 데이터셋 전달하기

만약 `--train_data_dir` 플래그를 통해, 특정 디렉토리를 학습데이터를 전달하면, 해당 폴더 안의 모든 이미지들이 학습에 사용됩니다.

```bash
data_dir/xxx.png
data_dir/xxy.png
data_dir/[...]/xxz.png
```

```bash
accelerate launch train_unconditional.py \
    --train_data_dir <path-to-train-directory> \
    <other-arguments>
```

내부적으로 해당 스크립트는 폴더를 🤗 Dataset 오브젝트로 자동으로 변환해주는 [`ImageFolder`](https://huggingface.co/docs/datasets/v2.0.0/en/image_process#imagefolder)라는 피처를 사용하고 있습니다.



### 데이터를 허브에 업로드 하기 (가능하면 비공개로!)

여러분의 데이터셋을 [`ImageFolder`](https://huggingface.co/docs/datasets/v2.0.0/en/image_process#imagefolder) 피처를 통해  허브에 업로드하는 것은 아주 간단하고 편리합니다. 아래 코드를 실행해봅시다.

```python
from datasets import load_dataset

# example 1: local folder
dataset = load_dataset("imagefolder", data_dir="path_to_your_folder")

# example 2: local files (supported formats are tar, gzip, zip, xz, rar, zstd)
dataset = load_dataset("imagefolder", data_files="path_to_zip_file")

# example 3: remote files (supported formats are tar, gzip, zip, xz, rar, zstd)
dataset = load_dataset(
    "imagefolder",
    data_files="https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip",
)

# example 4: providing several splits
dataset = load_dataset(
    "imagefolder", data_files={"train": ["path/to/file1", "path/to/file2"], "test": ["path/to/file3", "path/to/file4"]}
)
```

`ImageFolder`는 PIL로 인코딩된 이미지를 포함하는 `image` 컬럼을 만듭니다.

그 다음 허브로 업로드하면 됩니다.

```python
# assuming you have ran the huggingface-cli login command in a terminal
dataset.push_to_hub("name_of_your_dataset")

# if you want to push to a private repo, simply pass private=True:
dataset.push_to_hub("name_of_your_dataset", private=True)
```

이제 `--dataset_name` 인자를 허브에 등록된 여러분의 데이터셋 이름으로 설정하는 것만으로 간단하게 모델을 학습시킬 수 있습니다. 더 자세한 내용은 [이 블로그 포스트](https://huggingface.co/blog/image-search-datasets)를 참고해주세요.